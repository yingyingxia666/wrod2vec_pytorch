{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "基于WordAVGModel模型的情感分析.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.**导入数据**"
      ],
      "metadata": {
        "id": "xS6dHGqkbzuq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Cv6zUyaLWOII"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext.legacy.data import Field,LabelField,BucketIterator\n",
        "seed=1111\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "TEXT = Field(tokenize='spacy',tokenizer_language='en_core_web_sm')\n",
        "LABEL = LabelField(dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy import datasets\n",
        "train_data,test_data = datasets.IMDB.splits(TEXT,LABEL)"
      ],
      "metadata": {
        "id": "43tpcpcOWbqf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #查看数据集\n",
        "vars(train_data.examples[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg19IhrOXXPD",
        "outputId": "5562bd42-fe96-4754-82ea-3d27cce1bd7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'pos',\n",
              " 'text': ['Amazing',\n",
              "  'documentary',\n",
              "  '.',\n",
              "  'Saw',\n",
              "  'it',\n",
              "  'on',\n",
              "  'original',\n",
              "  'airdate',\n",
              "  'and',\n",
              "  'on',\n",
              "  'DVD',\n",
              "  'a',\n",
              "  'few',\n",
              "  'times',\n",
              "  'in',\n",
              "  'the',\n",
              "  'last',\n",
              "  'few',\n",
              "  'years',\n",
              "  '.',\n",
              "  'I',\n",
              "  'was',\n",
              "  'shocked',\n",
              "  'that',\n",
              "  'it',\n",
              "  'was',\n",
              "  \"n't\",\n",
              "  'even',\n",
              "  'nominated',\n",
              "  'for',\n",
              "  'a',\n",
              "  'Best',\n",
              "  'Documentary',\n",
              "  'Oscar',\n",
              "  'for',\n",
              "  '2002',\n",
              "  ',',\n",
              "  'the',\n",
              "  'year',\n",
              "  'it',\n",
              "  'was',\n",
              "  'released',\n",
              "  '.',\n",
              "  'No',\n",
              "  'other',\n",
              "  'documentary',\n",
              "  'even',\n",
              "  'comes',\n",
              "  'close.<br',\n",
              "  '/><br',\n",
              "  '/>It',\n",
              "  'was',\n",
              "  'on',\n",
              "  'TV',\n",
              "  'recently',\n",
              "  'for',\n",
              "  'the',\n",
              "  '5th',\n",
              "  'anniversary',\n",
              "  ',',\n",
              "  'but',\n",
              "  'I',\n",
              "  'missed',\n",
              "  'the',\n",
              "  'added',\n",
              "  '\"',\n",
              "  'where',\n",
              "  'are',\n",
              "  'they',\n",
              "  'now',\n",
              "  '\"',\n",
              "  'segment',\n",
              "  'at',\n",
              "  'the',\n",
              "  'end',\n",
              "  ',',\n",
              "  'except',\n",
              "  'I',\n",
              "  'did',\n",
              "  'catch',\n",
              "  'that',\n",
              "  'tony',\n",
              "  'now',\n",
              "  'works',\n",
              "  'for',\n",
              "  'the',\n",
              "  'hazmat',\n",
              "  'unit.<br',\n",
              "  '/><br',\n",
              "  \"/>I've\",\n",
              "  'seen',\n",
              "  'criticism',\n",
              "  'on',\n",
              "  'documentary',\n",
              "  'film',\n",
              "  '-',\n",
              "  'making',\n",
              "  'from',\n",
              "  'a',\n",
              "  'few',\n",
              "  'on',\n",
              "  'this',\n",
              "  'list',\n",
              "  '.',\n",
              "  'I',\n",
              "  'ca',\n",
              "  \"n't\",\n",
              "  'see',\n",
              "  'how',\n",
              "  'this',\n",
              "  'could',\n",
              "  'have',\n",
              "  'been',\n",
              "  'done',\n",
              "  'any',\n",
              "  'different',\n",
              "  '.',\n",
              "  'They',\n",
              "  'had',\n",
              "  'less',\n",
              "  'than',\n",
              "  '6',\n",
              "  'months',\n",
              "  'to',\n",
              "  'assemble',\n",
              "  'this',\n",
              "  'and',\n",
              "  'get',\n",
              "  'it',\n",
              "  'on',\n",
              "  'the',\n",
              "  'air',\n",
              "  '.',\n",
              "  'The',\n",
              "  'DVD',\n",
              "  'contains',\n",
              "  'more',\n",
              "  'material',\n",
              "  'and',\n",
              "  'background.<br',\n",
              "  '/><br',\n",
              "  \"/>I'm\",\n",
              "  'also',\n",
              "  'surprised',\n",
              "  'that',\n",
              "  'according',\n",
              "  'to',\n",
              "  'IMDb.com',\n",
              "  ',',\n",
              "  'the',\n",
              "  'brother',\n",
              "  'have',\n",
              "  'had',\n",
              "  'no',\n",
              "  'projects',\n",
              "  'in',\n",
              "  'the',\n",
              "  'four',\n",
              "  'years',\n",
              "  'since',\n",
              "  '.',\n",
              "  'What',\n",
              "  'have',\n",
              "  'they',\n",
              "  'been',\n",
              "  'doing',\n",
              "  '?']}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.**切分数据集**"
      ],
      "metadata": {
        "id": "nsgA9naqb7fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "#切分数据集 默认0.7\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(seed))\n",
        "print(f'训练集数量: {len(train_data)}')\n",
        "print(f'验证集数量: {len(valid_data)}')\n",
        "print(f'测试集合数量: {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3cz5oCrXb0J",
        "outputId": "b2b29c3e-4d94-44fd-f961-eeae188aa01e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练集数量: 17500\n",
            "验证集数量: 7500\n",
            "测试集合数量: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.**训练集构造词汇表**"
      ],
      "metadata": {
        "id": "b6BUrU-3bwSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#使用预训练glove模型，更新之后作为词向量\n",
        "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\", unk_init=torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data) "
      ],
      "metadata": {
        "id": "Sk2KhTKVXwig"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"词汇表中词数: {len(TEXT.vocab)}\")\n",
        "print(f\"label数: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o3DECo9cXGP",
        "outputId": "0339b5b2-b178-4ef3-cf9b-da1d4453e5fd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "词汇表中词数: 25002\n",
            "label数: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.**创建迭代器**"
      ],
      "metadata": {
        "id": "tzwb2AXici3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data),batch_size=BATCH_SIZE,device=device)"
      ],
      "metadata": {
        "id": "Zp-d7sf0YbnZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(train_iterator)).label.shape)\n",
        "print(next(iter(train_iterator)).text.shape)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rfOeqWBYqxG",
        "outputId": "84078636-e48d-4801-92ec-550d683e3021"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64])\n",
            "torch.Size([986, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iterator))\n",
        "print(batch.text.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eroshhgzYtBO",
        "outputId": "00fd1d26-1f5c-4415-ead9-80b7678c1288"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1153, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.构造Word Averaging模型**"
      ],
      "metadata": {
        "id": "Yf_udL5ocpbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class WordAVGModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx) \n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text): \n",
        "        embedded = self.embedding(text)  \n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        \n",
        "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1)   \n",
        "\n",
        "        return self.fc(pooled)\n",
        "VOCAB_SZIE = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1 \n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "\n",
        "model = WordAVGModel(VOCAB_SZIE, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)"
      ],
      "metadata": {
        "id": "5HK_gtd_Y9an"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.**初始化参数**"
      ],
      "metadata": {
        "id": "lw2oxItjczQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#用glove.6B.100d的参数作为初始化参数\n",
        "pretrained_embeddings = TEXT.vocab.vectors \n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BAqdUO3ZK9c",
        "outputId": "a72f3427-fb25-4c98-cffe-91b791ffd0f2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1065,  0.1614, -0.6850,  ..., -0.9348, -0.4778,  1.1286],\n",
              "        [ 0.2091,  0.2932,  0.3151,  ...,  1.1860, -1.5726,  1.1354],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.2572,  0.4990,  0.7320,  ..., -0.6175, -0.5058,  0.4684],\n",
              "        [ 0.0701,  0.4941,  0.1676,  ...,  0.1009, -0.4823,  0.4224],\n",
              "        [-0.2552, -0.7599, -1.0630,  ...,  0.1064, -0.8649, -1.0150]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM) \n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "xIuIGoQVZM4o"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.**模型训练**"
      ],
      "metadata": {
        "id": "s7vtLoURc3e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters()) \n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device) \n",
        "loss_fn = loss_fn.to(device) "
      ],
      "metadata": {
        "id": "PeNpd9A3ZNqO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y): \n",
        "    '''计算准确度，即预测和实际标签的相匹配的个数'''\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds)) \n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(model, iterator, optimizer, loss_fn):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    total_len = 0\n",
        "    model.train() \n",
        "    \n",
        "    for batch in iterator: \n",
        "        optimizer.zero_grad() \n",
        "        preds = model(batch.text).squeeze(1)\n",
        "        loss = loss_fn(preds, batch.label)\n",
        "        acc = binary_accuracy(preds, batch.label)\n",
        "             \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        \n",
        "        epoch_loss += loss.item() * len(batch.label)\n",
        "\n",
        "        \n",
        "        epoch_acc += acc.item() * len(batch.label)\n",
        "\n",
        "        \n",
        "        total_len += len(batch.label)\n",
        "\n",
        "        \n",
        "    return epoch_loss / total_len, epoch_acc / total_len"
      ],
      "metadata": {
        "id": "v1LcuGXVZQxF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    total_len = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():  \n",
        "        for batch in iterator: \n",
        "            \n",
        "            preds = model(batch.text).squeeze(1)\n",
        "            loss = loss_fn(preds, batch.label)\n",
        "            acc = binary_accuracy(preds, batch.label)\n",
        "            \n",
        "            epoch_loss += loss.item() * len(batch.label)\n",
        "            epoch_acc += acc.item() * len(batch.label)\n",
        "            total_len += len(batch.label)\n",
        "    model.train()\n",
        "    return epoch_loss / total_len, epoch_acc / total_len\n",
        "import time \n",
        "\n",
        "def epoch_time(start_time, end_time): \n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "Motj8yrCZRVL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf') \n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn) \n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss: \n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'wordavg-model.pth')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJLGglLCZYPU",
        "outputId": "0c0e6d39-e51c-49a1-f4eb-8e531a6e6ec5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.685 | Train Acc: 58.59%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 67.49%\n",
            "Epoch: 02 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.644 | Train Acc: 75.45%\n",
            "\t Val. Loss: 0.497 |  Val. Acc: 77.37%\n",
            "Epoch: 03 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.570 | Train Acc: 80.12%\n",
            "\t Val. Loss: 0.430 |  Val. Acc: 80.77%\n",
            "Epoch: 04 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.497 | Train Acc: 83.47%\n",
            "\t Val. Loss: 0.402 |  Val. Acc: 83.67%\n",
            "Epoch: 05 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.436 | Train Acc: 86.12%\n",
            "\t Val. Loss: 0.403 |  Val. Acc: 84.87%\n",
            "Epoch: 06 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.385 | Train Acc: 88.06%\n",
            "\t Val. Loss: 0.411 |  Val. Acc: 85.99%\n",
            "Epoch: 07 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.345 | Train Acc: 89.19%\n",
            "\t Val. Loss: 0.419 |  Val. Acc: 86.65%\n",
            "Epoch: 08 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.317 | Train Acc: 90.29%\n",
            "\t Val. Loss: 0.438 |  Val. Acc: 87.12%\n",
            "Epoch: 09 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.290 | Train Acc: 91.02%\n",
            "\t Val. Loss: 0.454 |  Val. Acc: 87.55%\n",
            "Epoch: 10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.269 | Train Acc: 91.65%\n",
            "\t Val. Loss: 0.470 |  Val. Acc: 87.84%\n",
            "Epoch: 11 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.251 | Train Acc: 92.22%\n",
            "\t Val. Loss: 0.486 |  Val. Acc: 88.05%\n",
            "Epoch: 12 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.236 | Train Acc: 92.75%\n",
            "\t Val. Loss: 0.501 |  Val. Acc: 88.33%\n",
            "Epoch: 13 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.221 | Train Acc: 93.22%\n",
            "\t Val. Loss: 0.517 |  Val. Acc: 88.67%\n",
            "Epoch: 14 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.207 | Train Acc: 93.68%\n",
            "\t Val. Loss: 0.535 |  Val. Acc: 88.69%\n",
            "Epoch: 15 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.195 | Train Acc: 94.02%\n",
            "\t Val. Loss: 0.550 |  Val. Acc: 88.89%\n",
            "Epoch: 16 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.183 | Train Acc: 94.49%\n",
            "\t Val. Loss: 0.568 |  Val. Acc: 88.88%\n",
            "Epoch: 17 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.174 | Train Acc: 94.72%\n",
            "\t Val. Loss: 0.586 |  Val. Acc: 88.75%\n",
            "Epoch: 18 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.164 | Train Acc: 95.16%\n",
            "\t Val. Loss: 0.600 |  Val. Acc: 89.25%\n",
            "Epoch: 19 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.155 | Train Acc: 95.47%\n",
            "\t Val. Loss: 0.615 |  Val. Acc: 89.13%\n",
            "Epoch: 20 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.146 | Train Acc: 95.79%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 89.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.**预测**"
      ],
      "metadata": {
        "id": "FF5dheSQdDy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy  \n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "\n",
        "def predict_sentiment(sentence):\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] \n",
        "    print(tokenized)\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized] \n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1) \n",
        "    pred = torch.sigmoid(model(tensor))\n",
        "    return pred.item()\n"
      ],
      "metadata": {
        "id": "aAyW6-zHaGad"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"I love This film\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj8jJ465aLGF",
        "outputId": "dd1788f8-997c-4b77-8821-25510b447ca7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'This', 'film', 'bad']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999997615814209"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}